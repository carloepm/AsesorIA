{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DOCUMENTO DE PRUEBA GOOGLE AI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OBJETIVOS :\n",
    "- Lograr una respuesta preliminar con el modelo.\n",
    "- Integrarle un prompt y memoria.\n",
    "- integrar el LLM al modulo del proyecto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DOCUMENTACION :\n",
    "\n",
    "https://python.langchain.com/docs/integrations/llms/google_ai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***OBJETIVO NUMERO 1***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import GoogleGenerativeAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from getpass import getpass\n",
    "api_key = getpass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hola, estoy bien, gracias por preguntar. ¿Cómo estás tú?\n"
     ]
    }
   ],
   "source": [
    "#EN ESTE CASO SOLO USAMOS EL LLM PARA VERIFICAR UNA RESPUESTA RAPIDA\n",
    "llm = GoogleGenerativeAI(model=\"gemini-1.0-pro\", google_api_key=api_key)\n",
    "print(\n",
    "    llm.invoke(\n",
    "        \"hola chat, como estas!\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**OBJETIVO NUMERO 2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.memory import ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RESPUESTA PRELIMINAR CON PROMPT DEFINIDO\n",
    "llm = GoogleGenerativeAI(model=\"gemini-1.0-pro\", google_api_key=api_key)\n",
    "# Notice that \"chat_history\" is present in the prompt template\n",
    "template = \"\"\"You are a nice chatbot having a conversation with a human.\n",
    "\n",
    "Previous conversation:\n",
    "{chat_history}\n",
    "\n",
    "New human question: {question}\n",
    "Response:\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "# Notice that we need to align the `memory_key`\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", input_key='question', return_messages=True, output_key='text')\n",
    "chain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=prompt,\n",
    "    verbose=True,\n",
    "    memory=memory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYou are a nice chatbot having a conversation with a human.\n",
      "\n",
      "Previous conversation:\n",
      "[HumanMessage(content='hola chat'), AIMessage(content='Hola, ¿cómo estás?'), HumanMessage(content='muy bien, me gustaria saber que es un LLM'), AIMessage(content='Un LLM (Large Language Model) es un tipo de inteligencia artificial (IA) que se utiliza para procesar y generar texto. Los LLM están entrenados en conjuntos de datos masivos de texto y pueden comprender y producir lenguaje humano de forma similar a la de un hablante nativo.\\n\\nAlgunos de los usos más comunes de los LLM incluyen:\\n\\n* **Generación de texto:** Los LLM se pueden utilizar para generar texto nuevo, como artículos, historias, poemas y diálogos.\\n* **Traducción:** Los LLM se utilizan para traducir texto de un idioma a otro.\\n* **Resumen:** Los LLM se pueden utilizar para resumir textos largos en resúmenes más cortos y fáciles de leer.\\n* **Clasificación:** Los LLM se pueden utilizar para clasificar texto en categorías, como noticias, deportes o entretenimiento.\\n* **Respuesta a preguntas:** Los LLM se pueden utilizar para responder preguntas sobre el mundo.\\n\\nLos LLM se están utilizando en una amplia variedad de aplicaciones, como chatbots, asistentes virtuales y motores de búsqueda.')]\n",
      "\n",
      "New human question: Genial, que es un LLM Open source?\n",
      "Response:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "respuesta = chain({'question':\"Genial, que es un LLM Open source?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Un LLM (Large Language Model) de código abierto es un tipo de IA (Inteligencia Artificial) que está disponible gratuitamente para que cualquiera pueda usarlo y modificarlo. Esto significa que los investigadores y desarrolladores pueden acceder al código subyacente del LLM y ajustarlo para sus propias necesidades específicas.\\n\\nAlgunos de los LLM de código abierto más populares incluyen:\\n\\n* GPT-3 de OpenAI\\n* BLOOM de BigScience\\n* OPT de Meta AI\\n\\nLos LLM de código abierto tienen varias ventajas sobre los LLM propietarios:\\n\\n* **Transparencia:** El código subyacente de los LLM de código abierto está disponible para que todos lo inspeccionen, lo que permite a los investigadores y desarrolladores comprender mejor cómo funcionan y tomar decisiones informadas sobre su uso.\\n* **Personalización:** Los LLM de código abierto se pueden personalizar para satisfacer necesidades específicas, como entrenar el modelo en un conjunto de datos particular o ajustar la arquitectura del modelo.\\n* **Colaboración:** Los LLM de código abierto fomentan la colaboración entre investigadores y desarrolladores, ya que pueden compartir y mejorar los modelos abiertamente.\\n\\nLos LLM de código abierto se utilizan en una amplia variedad de aplicaciones, como:\\n\\n* **Chatbots:** Los LLM de código abierto se pueden utilizar para crear chatbots que pueden comprender y responder al lenguaje humano de forma similar a la de un hablante nativo.\\n* **Asistentes virtuales:** Los LLM de código abierto se pueden utilizar para crear asistentes virtuales que pueden ayudar a los usuarios con una variedad de tareas, como programar citas, buscar información o controlar dispositivos domésticos inteligentes.\\n* **Motores de búsqueda:** Los LLM de código abierto se pueden utilizar para crear motores de búsqueda que pueden comprender y responder a consultas de búsqueda complejas de forma más efectiva.\\n\\nA medida que los LLM de código abierto continúan desarrollándose, se espera que desempeñen un papel cada vez más importante en el avance de la IA y la resolución de problemas del mundo real.'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "respuesta['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.memory import ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RESPUESTA PRELIMINAR CON PROMPT PERSONALIZADO\n",
    "llm = GoogleGenerativeAI(model=\"gemini-1.0-pro\", google_api_key=api_key)\n",
    "\n",
    "template = \"\"\"Sos un asesor AI dispuesto a asistir a los usuarios en diferentes tareas y proyectos que ellos tengan..\n",
    "\n",
    "Previous conversation:\n",
    "{chat_history}\n",
    "\n",
    "New human question: {question}\n",
    "Response:\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\",input_key='question', return_messages=True, output_key=\"text\")\n",
    "chain = LLMChain(llm=llm,prompt=prompt,verbose=True,memory=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSos un asesor AI dispuesto a asistir a los usuarios en diferentes tareas y proyectos que ellos tengan..\n",
      "\n",
      "Previous conversation:\n",
      "[]\n",
      "\n",
      "New human question: Hola chat! como esta la situacion del dengue en argentina?\n",
      "Response:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "respuesta = chain.invoke({'question':'Hola chat! como esta la situacion del dengue en argentina?'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hola, según los últimos datos disponibles, la situación del dengue en Argentina es la siguiente:\\n\\n* **Casos confirmados:** En 2022, se notificaron 9.500 casos confirmados de dengue en el país.\\n* **Provincias afectadas:** Las provincias más afectadas fueron Salta, Chaco, Jujuy, Tucumán y Formosa.\\n* **Fallecimientos:** Hasta el momento, se han registrado 6 fallecimientos por dengue en Argentina en 2022.\\n* **Situación actual:** La transmisión del virus del dengue continúa activa en algunas zonas del país, especialmente en el norte.\\n\\n**Recomendaciones:**\\n\\nPara prevenir el dengue, es importante tomar medidas como:\\n\\n* Eliminar posibles criaderos de mosquitos (agua estancada en recipientes, neumáticos, etc.).\\n* Usar repelente de insectos.\\n* Usar ropa que cubra la mayor parte del cuerpo.\\n* Colocar mosquiteros en ventanas y puertas.\\n* Consultar al médico ante síntomas como fiebre alta, dolor de cabeza intenso y dolor muscular.\\n\\n**Fuentes:**\\n\\n* Ministerio de Salud de la Nación: https://www.argentina.gob.ar/salud/dengue\\n* Organización Panamericana de la Salud (OPS): https://www.paho.org/es/temas/dengue\\n\\n**Nota:** La información proporcionada es general y no sustituye el consejo médico profesional. Si tienes síntomas de dengue, consulta a un médico de inmediato.'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "respuesta['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***OBJETIVO NUMERO 3***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esquema de Asesor del proyecto.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#AGREGANDO HERRAMIENTA DE BUSQUEDA PARA EL AGENTE\n",
    "import os\n",
    "os.environ[\"SERPER_API_KEY\"] = \"8b139823f4e8976b14208e65520107b9ba3607fa\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.agents import initialize_agent\n",
    "from langchain_community.utilities.google_serper import GoogleSerperAPIWrapper\n",
    "from langchain.tools import Tool\n",
    "from langchain.agents.agent_types import AgentType\n",
    "from langchain.prompts import MessagesPlaceholder\n",
    "\n",
    "def CrearAsesor():\n",
    "    #TEMPLATE PROXIMAMENTE MODIFICABLE\n",
    "        template = \"\"\"\n",
    "    Vas a asesor a los usuarios de la mejor manera, recordando sus nombres para ser mas amigable, si no sabes la respuesta no la inventes.\n",
    "    \n",
    "    Herramientas: {tools}, {tool_names}\n",
    "    Previous conversation:\n",
    "    {chat_history}\n",
    "    \n",
    "    New human question: {input}\n",
    "    {agent_scratchpad}\n",
    "    Response:\"\"\"\n",
    "\n",
    "\n",
    "        prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "        search = GoogleSerperAPIWrapper()\n",
    "\n",
    "        search_tool = Tool(\n",
    "            name=\"search_tool\",\n",
    "            description=\"Herramienta util para buscar informacion actualizada en internet.\",\n",
    "            func=search.run,\n",
    "            )\n",
    "        \n",
    "        tools = [search_tool]\n",
    "        memory = ConversationBufferMemory(memory_key=\"chat_history\", input_key='input', return_messages=True, output_key = 'output')\n",
    "        \n",
    "        llm = GoogleGenerativeAI(model=\"gemini-1.0-pro\", google_api_key=api_key)\n",
    "        \n",
    "        #chain = LLMChain(llm=llm,prompt=prompt,verbose=True,memory=memory)\n",
    "        chat_history = MessagesPlaceholder(variable_name=\"chat_history\")\n",
    "        \n",
    "#USAMOS INITIALIZE AGENT YA QUE PERMITE ESTRUCTURAR EL OUTPUT DEL AGENTE\n",
    "        agent = initialize_agent(tools,\n",
    "                         llm,\n",
    "                         agent=\"conversational-react-description\",\n",
    "                         verbose=True, agent_kwargs={\n",
    "                        \"prompt\":[prompt],\n",
    "                        \"memory_prompts\": [chat_history],\n",
    "                        \"input_variables\": [\"input\"]},\n",
    "                        memory = memory,\n",
    "                        handle_parsing_errors=True\n",
    "                        )\n",
    "\n",
    "        return agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "asesor_personal = CrearAsesor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: Do I need to use a tool? No\n",
      "AI: Sí, recuerdo tu nombre, Nicolás.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#LUEGO DE AGREGARLE EL PROMPT Y LA MEMORIA A AGENT_KWARGS, SE LOGRO QUE LLM DE GEMINI RECUERDE CONVERSACIONES.\n",
    "respuesta = asesor_personal.invoke({'input': 'Claro, ese concepto no entendia muy bien, perfecto, te pregunto, recordas mi nombre?'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sí, recuerdo tu nombre, Nicolás.'"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "respuesta['output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='hola chat, mi nombre es nicolas un gusto, quiero saber que es trading y a que se refieren con invertir en corto o en largo'),\n",
       " AIMessage(content='Hola Nicolás, encantado de conocerte. En pocas palabras, el trading es el acto de comprar y vender activos financieros, como acciones, bonos o divisas, con el objetivo de obtener ganancias. Invertir en corto significa apostar a que el precio de un activo caerá, mientras que invertir en largo significa apostar a que el precio de un activo subirá.'),\n",
       " HumanMessage(content='Claro, ese concepto no entendia muy bien, perfecto, te pregunto, recordas mi nombre?'),\n",
       " AIMessage(content='Sí, recuerdo tu nombre, Nicolás.')]"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "respuesta['chat_history']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NicoCH",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
